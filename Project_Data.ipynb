{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  trainingandtestdata.zip\n",
      "  inflating: data/testdata.manual.2009.06.14.csv  \n",
      "  inflating: data/training.1600000.processed.noemoticon.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2019-04-25 10:56:04--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81363704 (78M) [application/zip]\n",
      "Saving to: ‘trainingandtestdata.zip.3’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  130K 10m12s\n",
      "    50K .......... .......... .......... .......... ..........  0%  180M 5m6s\n",
      "   100K .......... .......... .......... .......... ..........  0%  259K 5m6s\n",
      "   ...\n", 
      " 79250K .......... .......... .......... .......... .......... 99% 97.0M 0s\n",
      " 79300K .......... .......... .......... .......... .......... 99% 67.9M 0s\n",
      " 79350K .......... .......... .......... .......... .......... 99%  142M 0s\n",
      " 79400K .......... .......... .......... .......... .......... 99% 67.3M 0s\n",
      " 79450K ......                                                100%  218M=6.3s\n",
      "\n",
      "2019-04-25 10:56:11 (12.2 MB/s) - ‘trainingandtestdata.zip.3’ saved [81363704/81363704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "wget \"http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\"\n",
    "unzip trainingandtestdata.zip -d data/\n",
    "iconv -f iso-8859-1 -t utf-8 < \"data/training.1600000.processed.noemoticon.csv\" > \"data/sentiment140data.csv\"\n",
    "cat data/sentiment140data.csv | perl -pe 's/\\\"\\,\\\"/\\\"\\t\\\"/g' > data/sentiment140.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0\"\t\"1467810369\"\t\"Mon Apr 06 22:19:45 PDT 2009\"\t\"NO_QUERY\"\t\"_TheSpecialOne_\"\t\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
      "\"0\"\t\"1467810672\"\t\"Mon Apr 06 22:19:49 PDT 2009\"\t\"NO_QUERY\"\t\"scotthamilton\"\t\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat data/sentiment140.csv | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x blitzer/blitzer   0 2009-03-09 05:57 sorted_data/\n",
      "drwxr-xr-x blitzer/blitzer   0 2007-05-07 01:29 sorted_data/dvd/\n",
      "...\n",
      "-rwxr-xr-x blitzer/blitzer          0 2007-05-04 22:29 sorted_data/tools_&_hardware/unlabeled.review\n",
      "-rwxr-xr-x blitzer/blitzer      97484 2007-05-04 22:29 sorted_data/tools_&_hardware/positive.review\n",
      "-rwxr-xr-x blitzer/blitzer     111698 2007-05-06 21:23 sorted_data/tools_&_hardware/all.review\n",
      "sorted_data/\n",
      "sorted_data/dvd/\n",
      "sorted_data/dvd/processed.review.balanced\n",
      "sorted_data/dvd/processed.review\n",
      "sorted_data/dvd/negative.review\n",
      "sorted_data/dvd/unlabeled.review\n",
      "...\n",
      "sorted_data/tools_&_hardware/positive.review\n",
      "sorted_data/tools_&_hardware/all.review\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#wget \"http://www.cs.jhu.edu/~mdredze/datasets/sentiment/unprocessed.tar.gz\"\n",
    "tar -ztvf unprocessed.tar.gz \n",
    "tar -zxvf unprocessed.tar.gz sorted_data/\n",
    "#iconv -f iso-8859-1 -t utf-8 < sorted_data/apparel/all.review > review_apparel.txt\n",
    "#mv review_apparel.txt data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting review_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile review_preprocessing.py\n",
    "\n",
    "#This script converts review_apparel.txt into a .csv file with a similar format as sentiment140.csv\n",
    "\n",
    "sentiment = []\n",
    "review = []\n",
    "previous = \"\"\n",
    "\n",
    "\n",
    "f = open(\"data/review_apparel.txt\", \"r\")\n",
    "for line in f:\n",
    "    if previous == '<rating>':\n",
    "        if line.strip() == \"1.0\" or line.strip() == \"2.0\":\n",
    "            sentiment.append(\"0\")\n",
    "        else:\n",
    "            sentiment.append(\"4\")\n",
    "        previous = line.strip()\n",
    "    elif previous.strip() == \"<review_text>\":\n",
    "        review.append(line)\n",
    "        previous = line.strip()\n",
    "    else: \n",
    "        previous = line.strip()\n",
    "\n",
    "f.close()\n",
    "\n",
    "data = list(zip(sentiment, review))\n",
    "\n",
    "for i in data: \n",
    "    print(i[0] + \"\\t\" + i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "python3 review_preprocessing.py | egrep -v '^$' > reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tI want to start by saying Fred Flare- shipped this product very fast!! And the transaction itself was very smooth. I do however, have extreme problems with the product itself. The product is not leather, its nylon, and it sort of looks cheap? The inside material is sued, but that's only the lining for the base of the wallet. Also, The wallet part is very hard to use. You cant really put too much in the wallet- The credit card slots are a little too snug, and there is no place for my I.D. The wallet included a small \"note book\" but it also doesn't fit in the wallet? I was very excited about this product, but now I feel duped. The pictures made the wallet seem like it was of higher quality, and that it was user friendly, but it's not. I do not recommend this product\n",
      "0\tI have to say that I was disappointed when I opened up the package containing my iPod wallet. It's cute, but not $60ish cute. First of all, it's not leather, it's nylon. The lining is indeed suede, but the photos in the product listing are misleading. I'm keeping it because the hassle of shipping it back, etc. isn't worth it. It does the job, but it wasn't what I was expecting. I feel ripped off\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat ../data/reviews.csv | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting balancing_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile balancing_data.py\n",
    "\n",
    "#Balancing data\n",
    "\n",
    "import random\n",
    "\n",
    "f = open(\"data/reviews.csv\", \"r\")\n",
    "all_positives = []\n",
    "negatives = []\n",
    "\n",
    "for line in f: \n",
    "    line = line.strip()\n",
    "    both = line.split(\"\\t\")\n",
    "    if both[0] == \"0\":\n",
    "        if len(both) == 2:\n",
    "            negatives.append(both)\n",
    "    else: \n",
    "        if len(both) == 2:\n",
    "            all_positives.append(both)\n",
    "f.close()\n",
    "\n",
    "random.seed(1234)\n",
    "positives = random.sample(all_positives, 150120) #len(negatives)=150120\n",
    "\n",
    "balanced_data = positives + negatives\n",
    "\n",
    "for i in balanced_data:\n",
    "    print(i[0] + \"\\t\" + i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "python3 balancing_data.py > reviews_balanced.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
